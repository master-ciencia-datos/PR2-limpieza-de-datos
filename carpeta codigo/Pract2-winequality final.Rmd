---
title: 'Práctica2: Limpieza y análisis de datos'
author: 'J.A. Ubieto y J. Lladó '
date: "Enero 2021"
output:
  html_document:
    toc: yes
  word_document:
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load_libraries, include=FALSE}
library(knitr)
library(readr)
library(ggplot2)
library(gridExtra)
library(tidyverse)
library(ggcorrplot)
library(corrplot)
library(MLmetrics)
library(randomForest)
library(caret)
```

# 1. Actividad práctica 2

## 1.1. Descripción

La siguiente actividad se realizará un caso práctico de tratamiento de conjunto de datos (dataset) que puede ser el creado en la práctica 1 anterior o bien cualquier dataset libre disponible en Kaggle (https://www.kaggle.com). El objetivo principal es aprender a identificar los datos relevantes para un proyecto analítico y utilizar las herramientas de integración, limpieza, validación y análisis de las mismas que aporta la programación con R.

## 1.2. Objetivos

Los objetivos concretos de esta práctica son:

● Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.

● Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.

● Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.

● Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.

● Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.

● Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.

● Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos. 

## 1.3. Competencias

En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:

● Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.

● Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis.


# 2. Desarrollo de la práctica

Para la realización de la práctica se escogió la base de datos winequality-red que se encuentra en el repositorio www.kaggle.com (https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009). La información proporcionada en la web sobre esta base de datos es la siguiente:

> "Los dos conjuntos de datos están relacionados con variantes tinto y blanco del vino portugués "Vinho Verde". Para más detalles, consulte la referencia [Cortez et al., 2009]. Debido a cuestiones de privacidad y logística, solo están disponibles las variables fisicoquímicas (entradas) y sensoriales (la salida) (por ejemplo, no hay datos sobre tipos de uva, marca de vino, precio de venta del vino, etc.).
Estos conjuntos de datos pueden verse como tareas de clasificación o regresión. Las clases están ordenadas y no equilibradas (por ejemplo, hay vinos mucho más normales que excelentes o malos)."

Después de observar el archivo de la base de datos, solo hay un único archivo .csv referente a los datos de los distintos vinos rojos. Esta base de datos está formada por 12 atributos y un total de 1599 entradas. También cabe considerar que el siguiente estudio se podría ampliar buscando la base de datos de vino blanco.  

Todo el desarrollo de la práctica y los archivos relacionados se encontrarán en el siguiente enlace Github:

https://github.com/master-ciencia-datos/PR2-limpieza-de-datos


## 2.1. Descripción de los datos

Se procede a la descripción de los distintos atributos de la base de datos winequality-red.csv. Las variables de entrada, basadas en test físico-químicos [Cortez et al., 2009] son:

**fixed_acidity:** conjunto de los ácidos naturales procedentes de la uva (tartárico, málico, cítrico y succínico) o formados en la fermentación maloláctica (láctico). … Sumada a la acidez volátil, da como resultado la acidez total de un vino. (tartaric acid - g / dm^3)

**volatile_acidity:** proviene de los ácidos de cadena corta de la serie acética (acético, fórmico, propiónico, butírico) y de algunas de sus combinaciones como el acetato de etilo originados durante la fermentación, que pueden proporcionar al vino el desagradable olor y sabor a “picado” arruinando la producción.(acetic acid - g / dm^3, Valores máximos aceptados 1.2-1.4 g/l)

**citric_acid:** (E-330) es un acidificante para corregir la acidez en mostos y vinos, además posee una acción estabilizante como antioxidante. El ácido cítrico forma complejos naturales con Fe(III), por tanto su adición puede reforzar esta acción secuestrando una cierta cantidad del hierro contenido en el vino. (g / dm^3)

**residual_sugar:** es la cantidad total de azúcar que queda en el vino que no ha sido fermentada por las levaduras, y parte de ese azúcar no fermentado son las Pentosas, azúcares presentes en el vino en concentraciones cercanas a 1 gramo por litro de mosto. Los pentosas son: Arabinosa. Xilosa. Es difícil encontrar vinos con cantidades inferiores a 1 gramo/litro, i vinos con cantidades superiores a 45 gramos/litro son considerados dulces (g / dm^3)

**chlorides:** Cantidad de sal en el vino. El contenido de cloruros en los vinos es variable, en general es inferior a 0,5 g/l, expresado en cloruro de sodio limite máximo por Ley, y excepcionalmente puede pasar de 1 g/l, sobre todo en viñedos ubicados en terrenos salinos o cerca del mar.(sodium chloride - g / dm^3)

**free_sulfur_dioxide:** La forma libre de SO2 existe en equilbrio entre el SO2 molecular (disuelto com gas) i el ion bisulfito, previene del crecimiento microbiológico y de la oxidación del vino.(mg / dm^3)

**total_sulfur_dioxide:** Cantidad total de SO2 libre y enlazadas de SO2. En concentraciones bajas, el SO2 es raramente indetectable en el vino, pero el SO2 libre a concentraciones por encima de 50 ppm (mg/L) SO2 se evidencia en el olfacto y el gusto.

**density:** La densidad del agua es cercana es parecida a la del vino, dependiendo la cantidad de alcohol y azúcares que contenga (mg / dm^3^).

**pH:** DEscribe com de ácido o básico es un vino. Los valores van de 0 (muy ácido) a 14 (muy básico). La mayoria de vinos se encuentran entre 3-4 de la escala del pH.

**sulphates:** Son aditivos del vino. Pueden contribuir a niveles dioxido de sulfuro SO2, que actua como antimicrobiano i antioxidante.Además, contribuyen a activar la fermentación alcohólica y tienen efectos sobre la maceración, el color, el olor y el gusto del vino.(potassium sulphate - g / dm^3^)

**alcohol:** Porcentaje de alcohol que contiene el vino (% volumen)

**quality:** Variable de salida (basada en datos sensoriales, sus valores van de 0 a 10)

## 2.2. Importancia del dataset

Después de la lectura inicial de la base de datos, se plantea que la cuestión ¿que vino tiene mayor calidad? Con esto se podría determinar que variables tienen mayor influencia en la calidad, por ejemplo, una mayor cantidad de alcohol implica una mejor calidad? La calidad del vino es influida por la presencia de ácido cítrico? ¿La calidad del vino es superior si éste tiene menos contenido de acidos volatiles?

Estudios anteriores, utilizaron este dataset para crear un modelo que pronostique la calidad de un vino según distintas variables fisico-químicas. Por lo tanto, se podría observar que variables influyen más, que relación habrían entre ellas e intentar crear un modelo de regresión predictivo de la calidad.
Con este modelo permitiría con solo un análisis físico-químico calificar un vino y en el caso que de tener datos económicos poner un precio a un nuevo vino.

## 2.3. Lectura y limpieza de datos

Se procederá a la lectura del archivo 'winequality-red' que se encuentra en formato CSV. Para ello se adjuntará en el documento final el archivo original, sin tener así necesidad de ir al enlace de la base de datos. Como se puede observar en el siguiente código la primera fila no se hará la lectura y se le daran los dintintos nombres de los atributos mediante names(). También se realizará la lectura de las 5 primeras entradas (head()).

```{r read}
##### Apertura y exploración de datos

df <- read.csv('winequality-red.csv', sep = ",", stringsAsFactors = FALSE, header = FALSE,  strip.white = T, skip=1)

names(df) <- c("fixed_acidity","volatile_acidity","citric_acid","residual_sugar","chlorides","free_sulfur_dioxide","total_sulfur_dioxide","density","pH","sulphates","alcohol","quality")

filas=dim(df)[1]
#Visualización de las 5 primeras entradas de la base de datos
head(df)
```

A continuación se mirará que tipo es cada atributo.

```{r Tipo atributos}
# Observación de los distintos tributos
sapply(df, function(x) class(x))
```

Como se puede observar todas las variables son numéricas menos la variable quality que es entera. Seguiremos buscando si en la base de datos hay algun valor vacío o valor no asignado.

```{r Valores vacíos}
colSums(is.na(df))
```

En este caso, no hay ningún valor vacío o no asignado. En el caso de que hubiese, se podría tratar de distintas formas, por ejemplo, hay bases de datos que para un valor vacío utilizan el carácter '?', entonces se trataría este carácter primero asignándolo como N.A.  (del inglés, Not Available) u 'otros' (dependiendo el tipo de variable que fuera). También se podrían imputar los valores N.A. como la media del resto de valores del atributo. Todos estos pasos dependerían del tipos de dato con el que estuviéramos trabajando. También cabe considerar que habría otra forma para determinar los valores vacíos de la base de datos, esta sería mediante la siguiente instrucción: #sapply(df, function(x) sum(is.na(x)))

Por último, en este apartado se visualizarán y analizarán los distintos valores extremos que haya en el dataset mediante diagama de caja y la función boxplot.stats().

```{r Diagrama de caja}
# Estructura general gráfica 2 filas, 6 columnas 
oldpar = par(mfrow = c(2,6))

#Realización de las distintas gráficas boxplot
for ( i in 1:12 ) {
  boxplot(df[[i]])
  mtext(names(df)[i], cex = 0.8, side = 1, line = 2)
}
```


```{r Valores extremos}
boxplot.stats(df$fixed_acidity)$out
boxplot.stats(df$volatile_acidity)$out
boxplot.stats(df$citric_acid)$out
boxplot.stats(df$residual_sugar)$out
boxplot.stats(df$chlorides)$out
boxplot.stats(df$free_sulfur_dioxide)$out
boxplot.stats(df$total_sulfur_dioxide)$out
boxplot.stats(df$density)$out
boxplot.stats(df$pH)$out
boxplot.stats(df$sulphates)$out
boxplot.stats(df$alcohol)$out
boxplot.stats(df$quality)$out
```

Después de su análisis, las variables 'volatile_acidity', 'chlorides', 'total_sulfur_dioxide' y 'sulphates' muestran valores extremos muy alejados. En este caso, se podrían dar es decir, estos valores podrían ser reproducibles en otros vinos y pueden tener significado, ya que por ejemplo valores elevados de ácidos volatiles ('volatile_acidity) o sulfitos (total_sulfur_dioxide) se relacionarían con una baja calidad del vino.


## 2.4. Análisis de datos

### 2.4.1. Selección de los grupos de datos a analizar/comparar

Inicialmente se utilitzarán todas las variables del dataset para el análisis estadístico. Primero de todo se observarán los distintos grupos de calidad que ya estan definidos, para ver cuantas observaciones hay en cada grupo

```{r observaciones por quality}
#Cantidad de muestras según variable quality calidad
table(df$quality)
```

Como se puede observar hay un total de 6 grupos, donde no aparecen la calidades inferiores a 3 y las superiores a 8, ya que en este dataSet no se ha dado el caso que hubiese vino de esta calidad. Por este motivo, se generará una nueva variable, que contenga menos grupos pero se contemple las calidades extremas. Esta nueva variable se llamara 'gruposcalidad' y quedará definida como: calidad Baja B<=4, Media M>4 y <6, Buena B>=6 y <7, Muy Buena MB>=7 y <9 y Premium P>=9. Con estos grupos, se podrán realizar distintos tests de hipótesis.

```{r Grupos de calidad}
#Creación grupos calidad según quality
df$gruposcalidad[df$quality<=4]<-0
df$gruposcalidad[df$quality>4 & df$quality<6]<-1
df$gruposcalidad[df$quality>=6 & df$quality<7]<-2
df$gruposcalidad[df$quality>=7 & df$quality<9]<-3
df$gruposcalidad[df$quality>=9]<-4

#Cantidad de observaciones según la variable gruposcalidad
table(df$gruposcalidad)
```

En este caso, se habrían generado 5 grupos, y vemos que almenos 4 de ellos contienen observaciones. Sólo el grupo con calidad Premium ha quedado sin datos. Estos resultados se tendrán en cuenta a la hora de hacer los distintos test de hipótesis.

Para el resto de atributos del dataset se buscarán si hay correlaciones entre ellos y se intentará realizar un modelo de regresión lineal con el objetivo de determinar la calidad del vino segun los distintos parámetros.

### 2.4.2. Comprobación de la normalidad y homogeneidad de la varianza

Para la comprobación de la normalidad de los datos, primero se haràn distintos histogramas de las variables para tener un primera visualización de su distribución.

```{r Representación distribución}
p1<-ggplot(df, aes(x = fixed_acidity)) + geom_histogram(fill = "blue")
p2<-ggplot(df, aes(x = volatile_acidity)) + geom_histogram(fill = "blue")
p3<-ggplot(df, aes(x = citric_acid)) + geom_histogram(fill = "blue")
p4<-ggplot(df, aes(x = residual_sugar)) + geom_histogram(fill = "blue")
p5<-ggplot(df, aes(x = chlorides)) + geom_histogram(fill = "blue")
p6<-ggplot(df, aes(x = free_sulfur_dioxide)) + geom_histogram(fill = "blue")
p7<-ggplot(df, aes(x = total_sulfur_dioxide)) + geom_histogram(fill = "blue")
p8<-ggplot(df, aes(x = density)) + geom_histogram(fill = "blue")
p9<-ggplot(df, aes(x = pH)) + geom_histogram(fill = "blue")
p10<-ggplot(df, aes(x = sulphates)) + geom_histogram(fill = "blue")
p11<-ggplot(df, aes(x = alcohol)) + geom_histogram(fill = "blue")
p12<-ggplot(df, aes(x = quality)) + geom_histogram(fill = "blue")

grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12, nrow = 6)
```

Como se puede observar, pocas de las variables podrían seguir una distribución normal, entre ellas podrían ser 'volatile_acidity', 'density' y 'pH'. Con el objetivo de verificar la suposición de la normalidad, se realizarán los tests de **Shapiro-Wilk** y de **Kolmogorov-Smirnov** para estas variables.

```{r Shapiro_test}
#Comprobación de la normalidad por Shapiro.test
shapiro.test(df$volatile_acidity)
shapiro.test(df$density)
shapiro.test(df$pH)
shapiro.test(df$quality)

```

```{r Kolmogorov - Smirnov}
ks.test(df$volatile_acidity, pnorm, mean(df$volatile_acidity), sd(df$volatile_acidity))
ks.test(df$density, pnorm, mean(df$density), sd(df$density))
ks.test(df$pH, pnorm, mean(df$pH), sd(df$pH))
ks.test(df$quality, pnorm, mean(df$quality), sd(df$quality))

```

Como se puede observar en los tests Shapiro-Wilk y Kolmogorov-Smirnov, los valores p-value obtenidos han sido inferiores a alpha=0.05 (nivel de significancia) indicancdo que la hipótesis nula es rechazada y por tanto los datos no cuentan con una distribución normal. Se verificarán también para el resto de variables con una adaptación de la función que planteó T. Gutiérrez (2017).

```{r shaprio test para todas las viables}
alpha = 0.05
col.names = colnames(df)
for (i in 1:ncol(df)) {
  if (i == 1) cat("Variables que no siguen una distribución normal:\n")
  if (is.integer(df[,i]) | is.numeric(df[,i])) {
    p_val = shapiro.test(df[,i])$p.value
    if (p_val < alpha) {
    cat(col.names[i])
    # Format output
    if (i < ncol(df) - 1) cat(", ")
    if (i %% 3 == 0) cat("\n")
    }
  }
}
```

Como se puede verificar todas la variables no siguen una distribución normal. Para el test de homogeneidad de las varianzas se aplicará el test de **Fligner-Killeen** ya que los datos no siguen la distribución normal. En este test, la hipótesis nula asume igualdad de varianzas en los diferentes grupos de datos, por lo que p-valores inferiores al nivel de significancia
indicarán heterocedasticidad. En este caso, primero se realizará en modo comparativo el test de la variable citric_acid con la variable quality y con la variable gruposcalidad, para observar como influye la agrupación con distintos niveles. Después se realizará una tabla con los valores p_value obtenidos de aplicar el test Fligner-Killen de las distintas variables con los distintos grupos de la variable gruposcalidad.

```{r flignertest}
#Comparación del test fligner con variable quality
fligner.test(citric_acid ~ quality, data = df)
fligner.test(citric_acid ~ gruposcalidad, data = df)

#tabla->Cálculo p_val de fligner test de las variables con los distintos de la variable gruposcalidad
tab.pvalue <- matrix(c('fixed_acidity', fligner.test(fixed_acidity ~ gruposcalidad, data = df)$p.value,
                        'volatile_acidity', fligner.test(volatile_acidity ~ gruposcalidad, data = df)$p.value,
                        'citric_acid', fligner.test(citric_acid ~ gruposcalidad, data = df)$p.value,
                        'residual_sugar', fligner.test(residual_sugar ~ gruposcalidad, data = df)$p.value,
                        'chlorides', fligner.test(chlorides~ gruposcalidad, data = df)$p.value,
                        'free_sulfur_dioxide', fligner.test(free_sulfur_dioxide ~ gruposcalidad, data = df)$p.value,
                        'total_sulfur_dioxide', fligner.test(total_sulfur_dioxide ~ gruposcalidad, data = df)$p.value,
                        'density', fligner.test(density ~ gruposcalidad, data = df)$p.value,
                        'pH', fligner.test(pH ~ gruposcalidad, data = df)$p.value,
                        'sulphates', fligner.test(sulphates ~ gruposcalidad, data = df)$p.value,
                        'alcohol', fligner.test(alcohol ~ gruposcalidad, data = df)$p.value),
                        ncol = 2, byrow = TRUE)
colnames(tab.pvalue) <- c("variable", "p_value")
tab.pvalue

```

Se puede observar un cambio, por el hecho de realizar el test Fligner-Killeen respeto a la variable quality o a la variable gruposcalidad. Por ejemplo, en la variable ácido citrico respecto a quality las varianzas entre los grupos son similares (p_value>0.05), en cambio, respecto a la variable gruposcalidad las varianzas entre grupos son distintas (p_value<0.05). Podemos decir, que el hecho de tener los datos en menos grupos, ha producido en este caso que las varianzas entre grupos sean distintas. 

Por lo que hace las variables'chlorites' y 'pH' con los niveles de la variable gruposcalidad, tienen varianzas similares ya que el valor p_value fue superior a 0.05 y no se pudo rechazar la hipótesis nula. Para el resto de variables las varianzas fueron distintas.  

### 2.4.3. Análisis estadístico

Se empezará el análisis estadístico de forma introductoria con el análisis estadístico descriptivo, ya que no se hizo en los anteriores apartados. También se realizarán tres pruebas estadísticas para intentar resolver las cuestiones o problemas planteados inicialmente.

#### 2.4.3.0. Análisis estadístico descriptivo

```{r análisis descriptivo}
summary (df)
```

Como se puede observar en el análisis estadístico las variables 'residual_sugar', 'free_sulfur_dioxide', 'total_sulfur_dioxide' se comfirma que tienen valores muy lejanos de los que podrían esperarse (sobretodo la variable total_sulfur_dioxide). Otro dato importante a analizar es la variable 'quality' en que se observa que la media de los vinos se encuentra en 5.636.Esto nos da una idea que en gran parte los vinos que se analiza son de un rango medio.

#### 2.4.3.1. Correlación entre variables

Se realizará la correlación de las distintas variables entre todas ellas, mediante el test de correlación **Spearman**, ya que las variables del estudio no siguen una distribución normal, en caso de que la hubieran seguido una distribución normal se hubiera aplicado la correlción de **Pearson**. Para determinar la correlación se utilizará la función cor() con el método 'Spearman', y se mostrarán los resultados con una figura en círculos y sus valores. Cuando mayor sean los circulos, mayor será su correlación. Y según su color, la correlación será positiva si es azul, y negativa si es roja. Respeto a los valores numéricos de la correlación, cuando más cercanos a +1 o -1 mayor será su correlación.

```{r correlación variables}
corr.res<-cor(df, method="spearman")
corrplot.mixed(corr.res,upper="circle",number.cex=.7,tl.cex=.8)
```

Como se puede observar la mayores correlaciones han sido para el conjunto de variables 'fixed_acidity'-'citric_acid' (correlación de 0.66), 'volatile_acidity'-'citric_acid' (-0.61),  'fixed_acidity'-'density' (0.62),  'fixed_acidity'-'pH' (-0.71) y 'alcohol'-'density' (-0.46).   

Para la variable de más interés 'quality', los valores de correlación han sido reativamente muy bajos, en que el coeficiente de dicha variable con la variable alcohol ha sido de 0.48, con 'volatile_acidity' -0.38 y con 'sulphates' de 0.38. 
Una de los motivos por el cual la correlación de las distintas variables con la variable calidad tengan valores bajos, podría ser que 'quality' sea de tipo entero y por tanto su rango de valores dentro de un mismo grupo no se muy elevado y en consecuencia no haya una nube de puntos muy definida.

A modo resumen se mostrarán la disposición de las muestras segun las variables 'fixed_acidity', 'citric_acid', 'density' y 'pH', con ello se puede observar las tendencias positivas y negativas de las relaciones entre variables.

```{r resumen visual}
df2<-subset(df, select=c(1,3,8,9))
pairs(df2[, colnames(df2)])
```

#### 2.4.3.2. Tests hipótesis 

Se realizarán distintos tests de hipótesis con el objetivo de resolver distintas cuestiones que se han planteado.

>¿La calidad del vino es superior si éste tiene menos contenido de acidos volatiles?

Para resolver esta cuestión se hará un test de hipótesis de dos muestras donde se comparan la distintas medias de cada una de ellas. Las muestras que se escogeran son el contenido de acidez volátil en función de lso grupos de calidad (gruposcalidad). Cabe recordar que el grupo de calidad =4 no tenia ninguna observación

```{r Grupos acidez_volatil respeto calidad}
va0<-df$volatile_acidity[df$gruposcalidad==0]
va1<-df$volatile_acidity[df$gruposcalidad==1]
va2<-df$volatile_acidity[df$gruposcalidad==2]
va3<-df$volatile_acidity[df$gruposcalidad==3]
```

Una vez realizado los distintos grupos se realizará un test de hipótesis, comparando una muestra de menor calidad, con la de máxima calidad (habrá un total de tres)

    Contraste de hipótesis de dos muestras (ácidos volátiles según calidad)
                
                H0 : µ1 = µ2  (Hipótesis nula)

                H1 : µ1 > µ2  (Hipótesis alternativa)

    Donde µ1 es la media de ácidos volátiles para vinos de menor calidad y µ2 es la media para vinos de mayor calidad (en todos los casos, ésta será siempre la de grupo de calidad 3).
    La hipótesis nula será que las dos medias sean iguales, en caso de no aceptar la hipótesis nula, la media de peor calidad será superior.

También se aprovechará para verificar el test de varianzas (homogeneidad) 

```{r Tests ácidos volátiles-calidad}
#verificación del test de varianzas
var.test(va0, va3)
#test hipótesis acidez volatil -- calidad
t.test(va0, va3, alternative="greater", var.equal=FALSE)
t.test(va1, va3, alternative="greater", var.equal=FALSE)
t.test(va2, va3, alternative="greater", var.equal=FALSE)
```

Como se pueden observar en los resultados, las medias de los distintos grupos analizados son distintas ya que el valor p-value del test ha sido en todos los casos inferior a alpha:0.05, por lo tanto no se acepta la hipótesis nula y la media de ácidos volátiles del grupo de peor calidad será superior al de mayor calidad. También se confirma que las dos varianzas de las muestras no son iguales. 

Estos resultados nos pueden permitir diferenciar las calidades según la cantidad de ácidos volatiles que tenga el vino, y por lo tanto, podría ser una de las variables clave para la modelización.

>¿La calidad del vino es superior si éste tiene más contenido de ácido cítrico?

Se procederá a realizar los grupos de ácido cítrico segun la variable grupos calidad del vino, igual que se hizo en la pregunta anterior.

```{r Grupos ácido cítrico respeto calidad}
ca0<-df$citric_acid[df$gruposcalidad==0]
ca1<-df$citric_acid[df$gruposcalidad==1]
ca2<-df$citric_acid[df$gruposcalidad==2]
ca3<-df$citric_acid[df$gruposcalidad==3]
```

    Contraste de hipótesis de dos muestras (ácido cítrico según calidad)
                
                H0 : µ1 = µ2  (Hipótesis nula)

                H1 : µ1 < µ2  (Hipótesis alternativa)

    Donde µ1 es la media de ácido cítrico para vinos de menor calidad y µ2 es la media de mayor calidad (en todos los casos, ésta será siempre la de calidad 7).
    La hipótesis nula será que las dos medias sean iguales, en caso de no aceptar la hipótesis nula, la media de peor calidad será inferior.

```{r Tests ácido cítrico-calidad}
#test de varianzas
var.test(ca0, ca3)

#test hipótesis ácido cítrico -- calidad
t.test(ca0, ca3, alternative="less", var.equal=TRUE)
t.test(ca1, ca3, alternative="less", var.equal=TRUE)
t.test(ca2, ca3, alternative="less", var.equal=TRUE)
```

En este caso sólo se hizo el test de hipótesis para los distintos grupos de calidad con el de mayor calidad (ca3). Se rechazo la hipótesis nula, ya que el valor de p-value fue inferior a 0.05, y se acepta que la media de ácido cítrico es inferior para los vinos de menor calidad respeto al de mayor calidad. También se verificó la no igualdad de varianzas entre los dos grupos.

>¿La calidad del vino es superior si éste tiene más contenido de alcohol?

Se procederá a realizar los grupos de alcohol segun los grupos de calidad del vino, igual que se hizo en la pregunta anterior.

```{r Grupos alcohol respeto calidad}
a0<-df$alcohol[df$gruposcalidad==0]
a1<-df$alcohol[df$gruposcalidad==1]
a2<-df$alcohol[df$gruposcalidad==2]
a3<-df$alcohol[df$gruposcalidad==3]
```

    Contraste de hipótesis de dos muestras (alcohol según calidad)
                
                H0 : µ1 = µ2  (Hipótesis nula)

                H1 : µ1 < µ2  (Hipótesis alternativa)

    Donde µ1 es la media alcohol para vinos de menor calidad (en todos los casos, ésta será siempre la de calidad 4) y µ2 es la media de mayor calidad .
    La hipótesis nula será que las dos medias sean iguales, en caso de no aceptar la hipótesis nula, la media de peor calidad será inferior.

```{r Tests alcohol-calidad}
#test de varianzas
var.test(a0, a3)

#test hipótesis alcohol -- calidad
t.test(a0, a1, alternative="less", var.equal=FALSE)
t.test(a0, a2, alternative="less", var.equal=FALSE)
t.test(a0, a3, alternative="less", var.equal=FALSE)
```

En este caso, los distintos tests mostraron distintos resultados, ya que la comparación entre los grupos a0 y a1, se tuvo que aceptar la hipótesis nula ya que la media de alcohol fue en la calidad inferior(gruposcalidad 0) fue superior a la grupocalidad 1. En cambio para el resto de tests, si que se rechazó la hipótesis nula y se aceptó que el contenido de alcohol era inferior.  

Por último y como objetivo final de la práctica, en los siguientes subapartados se realizarán distintos modelos de regresión lineal, regresión polinómica, random Forest, ... que permitan predir la calidad de un vino a partir de los distintos atributos analizados (todos ellos son regresores cuantitativos).

#### 2.4.3.3. Modelo predictivo regresión lineal

Se empezarán con la realización de distintos modelos de regresión lineal, para ello se crearán un grupo de datos de entreno y otro grupos que se utilizará como test. El método que se utilizará para la partición de datos es el método de exclusión, donde los datos se dividen aleatoriamente en dos conjuntos independientes, el de entrenamiento y el de test. Típicamente, dos tercios de los datos se asignan al conjunto de entrenamiento, y el tercio restante
se reserva para testear el modelo (L. Subirats et al(2019)). En nuestro caso, la muestra de entreno va a reprentar un 70% del dataset original.

```{r Datos train test}
# División de los datos en train y test, método exclusión

set.seed(250)
id_train <- sample(1:nrow(df), size = 0.7*nrow(df), replace = FALSE)

df.train <- df[id_train, ]
df.test  <- df[-id_train, ]
```

También con el objetivo de ver como varia la métrica de rendimiento R^2^ se generarán cuatro modelos con distintas variables y todos los datos del dataset y dos modelos con los datos de entreno (df.train). 

```{r modelos}
#Generación de modelos lineales
modelo1<- lm(gruposcalidad ~ alcohol + volatile_acidity + sulphates, data = df)
modelo2<- lm(gruposcalidad ~ volatile_acidity + sulphates + total_sulfur_dioxide + alcohol, data = df)
modelo3<- lm(gruposcalidad ~ volatile_acidity + sulphates + chlorides + total_sulfur_dioxide + alcohol + pH, data = df)
modelo4<- lm(gruposcalidad~. -quality, data=df)

#Modelos con entreno
modelo5<- lm(gruposcalidad ~ volatile_acidity + sulphates + chlorides + total_sulfur_dioxide + alcohol + pH, data = df.train)
modelo6<- lm(gruposcalidad~. -quality, data=df.train)
```

Las distintas métricas R^2^ obtenidas de los modelos se muestran en la siguiente tabla:

```{r Tabla coeficientes}
# Tabla con los coeficientes de determinación de cada modelo
tab.coeficientes <- matrix(c(1, summary(modelo1)$r.squared,
                              2, summary(modelo2)$r.squared,
                              3, summary(modelo3)$r.squared,
                              4, summary(modelo4)$r.squared,
                              5, summary(modelo5)$r.squared,
                              6, summary(modelo6)$r.squared),
                              ncol = 2, byrow = TRUE)
colnames(tab.coeficientes) <- c("Modelo", "R^2")
tab.coeficientes
```

El coeficiente R^2^ nos mide el grado que los distintos valores quedan ajustados en el modelo. Cuando este valor es cercano a 1, el modelo es considerado bueno, en cambio cuando el valor es mas cercano a 0, el modelo es considerado com malo. Como se puede observar en los distintos modelos de regresión lineal, el valor R^2^ es muy bajo, considerando que los modelos generados son de baja calidad o malos. También se observa que el hecho de introducir más variables en el modelo, el ajuste (R^2^) ha augmentado muy poco. No siempre con el augmento de variables en el modelo genera una mejor respuesta. Respeto a los modelos creados a partir de los datos de entreno (df.train) no hubo mejora con el coeficiente R^2^.

Para terminar la regresión lineal se hará la predicción de distintos valores considerados para vino buenos y malos, así como los datos de testeo (df.test)

```{r Predicción}
x1<-data.frame(volatile_acidity=0.25, sulphates=0.45, chlorides=0.08, total_sulfur_dioxide=0.4, alcohol=14.5, pH=2.9)
x2<-data.frame(volatile_acidity=1.4, sulphates=2.01, chlorides=0.45, total_sulfur_dioxide=150, alcohol=10, pH=3.7)
  
predict(modelo3, x1)
predict(modelo3, x2)
a<-predict(modelo6, df.test)
head(a)
predict(modelo5, x1)
predict(modelo5, x2)
```

Para intentar mejorar el modelo se crearán otros modelos mediante la regresión polinómica y el randonForest.

#### 2.4.3.4. Modelo predictivo regresión polinómica

Previo al siguiente modelo predictivo de regresión polinómica, se hicieron otros intentando observar cual podría ser el mejor. Los distintos R^2^ permanecían bajos, así que a continuación solo se mostrará un único modelo derivado del modelo 5 donde las variables 'sulphates' y 'pH' son liniales y cuadráticas (se puede observar en el sumario del modelo).

```{r Modelo polinomial}
modelo_pol1<- lm(gruposcalidad ~ volatile_acidity + poly(sulphates,2) + alcohol + chlorides + total_sulfur_dioxide +  poly(pH,2) , data = df.train)

summary(modelo_pol1)
```

Con este modelo generado (modelo_pol1) y el modelo 5 se van hacer comparaciones sobre distintas métricas de evaluación (R^2^, MSE, RMSE y MAE). Se generará una función para que nos de el resultado de cada una de ellas y se aplicará para los dos modelos.

```{r Función métricas}
indicator <- function(model, y_pred, y_true) {
     adj.r.sq <- summary(model)$adj.r.squared
     mse <- MSE(y_pred, y_true)
     rmse <- RMSE(y_pred, y_true)
     mae <- MAE(y_pred, y_true)
     print(paste0("Adjusted R-squared: ", round(adj.r.sq, 4)))
     print(paste0("MSE: ", round(mse, 4)))
     print(paste0("RMSE: ", round(rmse, 4)))
     print(paste0("MAE: ", round(mae, 4)))
}
#Métricas para modelo5
indicator(model = modelo5, y_pred = modelo5$fitted.values, y_true = df.train$gruposcalidad)
#Métricas para modelo_pol1
indicator(model = modelo_pol1, y_pred = modelo_pol1$fitted.values, y_true = df.train$gruposcalidad)
```

Como se puede observar los resuldos obtenido para el modelo siguen siendo de baja calidad o malos. Para intentar mejorar el modelo, se creará un modelo RandomForest.

#### 2.4.3.5. Modelo RandomForest

Para poder realizar un modelo RandomForest, será necesario pasar la variable dependiente a tipo 'factor'. Para ello se convertirá los datos de entreno df.train.

```{r Gruposcalidad}
#Conversión variable gruposcalidad a tipo factor
df.train$gruposcalidad<-as.factor(df.train$gruposcalidad)
```

Generamos modelo randomForest con todas las variables menos quality y utilizando los datos de entreno df.train. También se mostrarán los resultados obtenidos del modelo y se calculará la precisión de éste a partir de su matriz de confusión.

```{r RandomForest}
# Create random forest for regression 
quality.rf <- randomForest(gruposcalidad~. -quality, data = df.train)
# Resultados RandomForest
quality.rf
#Precisión train
(2+374+315+69)/nrow(df.train)
```

Con este modelo se ha calculado el OOB (out of bag error)  que es un método de la medida del error de predicción para los modelos RandomForest. En este caso ha sido del 32.08%. También se calculó la precisión del modelo con los datos de entreno que fue del 68.6%.

Para intentar mejorar este modelo RandomForest, se realizará un entrenamiento mediante la librería 'caret' train function. Se utilizará un método de validación cruzada (repeatedcv) de 5 veces y repetido 5 veces. El método 'repeatedcv' se utiliza para especificar la validación cruzada repetida de K veces (y el argumento repeticiones controla el número de repeticiones). 

```{r RandomForest con entreno}
df$gruposcalidad<-as.factor(df$gruposcalidad)
#Entreno y generación de modelo
t.ctrl <- trainControl(method = "repeatedcv", number = 5, repeats = 5)
rf.grid <- expand.grid(mtry = 1:11)
#Creación modelo a partir de los datos df.train
rf.train <- train(gruposcalidad ~ . -quality, data = df.train, method = "rf",
                  trControl = t.ctrl, tuneGrid = rf.grid,
                  preProcess = c("center", "scale"))
plot(rf.train)
```

Como se puede observar en el gràfico, el modelo llega a obtener una precisión entre el 65 y el 67% según la cantidad de distintos predictores (extraoficialmente, se probó este modelo con todos los datos y aplicadon cross validation, y se obtubo una precisión superior al 70%).

#### 2.4.3.7. Support vector machine (regresion)

De forma adicional e introductoria se realizará otro modelo, Support Vector Regresion (o también Suport Vector Machine, radial Kernel), para comparar con el resto de modelos. Los SVM son modelos de clasificación o de análisis de la regresión. Una máquina de vectores coge como entrada un set de datos y predice, por cada una de estas entradas a cuál de las dos posibles clases pertenece. Mediante el entrenamiento con datos de entrada previamente clasificadas, se establece un modelo que separa las dos clases entrantes. Este modelo N-dimensional establece una frontera entre las dos tipologías establecidas, esta se sitúa en el punto en el que la diferencia entre clases sea lo más grande posible y el margen de error sea cero (dataset separable) o mínimo (dataset no separable ). Se denominan vectores de apoyo a los puntos que conforman las dos líneas paralelas al hiperplano, siendo esta distancia la mayor posible (margen). 


Este modelo, igual que el segundo modelo RandomForest, también se utilizará un entrenamiento con validación cruzada. Se tendrán en cuenta el método para escoger los Kernels (núcleos) que fue el método radial basis function.

```{r Support Vector Machine}
svm.grid <- expand.grid(C = 2^(1:3), sigma = seq(0.1, 1, length = 10))
svm.mod <- train(gruposcalidad ~ . -quality, data = df.train, method = "svmRadial",
                   trControl = t.ctrl, tuneGrid = svm.grid,
                   preProcess = c("center", "scale"))
plot(svm.mod)
```

Como se puede ver en el gráfico anterior, la mejor precisión del modelo Support Vector Machine fue del 63% aproximandament, con un coste de 2 (dos grupos o hiperplanos) y sigma del 0.6.

#### 2.4.3.8. Comparación de modelos

Para finalizar la práctica se realizará una comparación de los distintos modelos: modelo 6 (modelo regresión lineal con todas la variables y datos entreno (método exclusión)), quality.rf (random forest con método de entreno exclusión) y rf.train (random forest con método de entreno validación cruzada a partir de los datos entreno anteriores). Para ello, se hará una predicción con los datos reservados para el test (df.test) y después se generará la matriz de confusión con los datos reales por medio de la función confusionMatrix(). La función confusionMatrix() estima los parámetres de precisión, sensibilidad y especificidad del modelo entre otros. (Nota: la predicción para el modelo6 (a) se redondeó y se transformó como factor)

```{r Precisión test}
#Matriz de confusión para modelo6 regresión lineal 
confusionMatrix(as.factor(round(a,0)), as.factor(df.test$gruposcalidad))

#MAtriz de confusión para modelo randomForest con método entrenamiento de exclusión
proba<-predict(quality.rf, newdata = df.test)
confusionMatrix(as.factor(proba), as.factor(df.test$gruposcalidad))

#MAtriz de confusión para modelo randomForest con método entrenamiento validación cruzada
rf.pred2 <- predict(rf.train, df.test)
confusionMatrix(as.factor(rf.pred2), as.factor(df.test$gruposcalidad))

#Matriz confusión modelo SVM con método entrenamiento validación cruzada
svm.test <- predict(svm.mod, df.test)
confusionMatrix(as.factor(svm.test), as.factor(df.test$gruposcalidad))
```

Con estos resultados se pueden comparar los distintos modelos en los tests posteriores. La mayor precisión fueron por los dos modelos randomForest, aproximadamente del 68%, seguido del SVM 64% y por último el modelo de regresión lineal (61%, donde se tuvieron que redondear los valores predecidos, si se hubiese truncado la precisión hubiera sido peor). También se obtuvo la sensibilidad y especificidad de estos modelos para los distintos grupos, la mayor sensibilidad (verdaderos positivos) fue detectada para la clase 1 (aprox.77.7% rf.pred) y la mayor especificidad (Verdaderos negativos) para la clase 0. Las peores sensibilidades fueron detectadas para la clase 3

```{r obtencion csv final, include=FALSE}
write.csv(df, file = 'vinofinal.csv', append = FALSE)
```

# 4. Conclusión

En la presente práctica de limpieza y análisis de datos se escogió un dataSet referente a la calidad de un vino (distintas variables físico-químicas) con el objetivo de responder distintas preguntas y crear un modelo predictivo de la calidad del vino.

- La primera parte de la práctica se realizó una limpieza de los datos, donde todas las variables eran del tipo numérico y todas ellas mostraban valores extremos  outliers. En nuestro caso, estos valores extremos o outliers no se eliminaron ya que podrían darse en situaciones reales. 

- En la segunda parte, análisis de datos, se analizó la normalidad de los datos, donde se observó que ninguna de las variables seguía una función normal, y las variable pH y Chlorides mostraban igualdad de varianzas respeto la variable quality (el resto de variables sus varianzas eran distintas).

- En el análisis estadístico, se realizó un análisis descriptivo de las variables, se determinó la correlación que había entre las distintas variables y se realizaron distintos test de hipótesis con el objetivo de resolver distintas preguntas. De forma general se observó poca correlación entre variables, las mayores fueron para los conjuntos de variables ‘fixed_acidity’-‘citric_acid’ (correlación de 0.66), ‘volatile_acidity’-‘citric_acid’ (-0.61), ‘fixed_acidity’-‘density’ (0.62), ‘fixed_acidity’-‘pH’ (-0.71) y ‘alcohol’-‘density’ (-0.46). También se comprobó que a una mayor calidad del vino la presencia de ácidos volátiles será inferior y también tendrán mayor cantidad de ácido cítrico. Respeto a la cantidad de alcohol, los distintos test de hipótesis realizados mostraron distintos resultados y no se pudo verificar de forma general que los vinos de mayor calidad tuviesen mayor contenido de alcohol.  

- Por último se realizaron distintos modelos predictivos para la variable calidad. Se pudo comparar los métodos de regresión lineal múltiple, regresión polinómica, random Forest y se empezó a estudiar un modelo vector support machine o regression. También se utilizaron distintas formas para la partición de los datos (exclusión y validación cruzada) y se utilizaron distintas métricas de rendimiento para la comparación de los modelos. De forma general y en este caso, se concluyó que los modelos RandomForest fueron los que mayor precisión tenían para la predicción de la calidad de los vinos.


# 5. Bibliografía

J. Gibergans (2018) Regresión lineal simple. Universitat Oberta de Catalunya

J. Gibergans (2018) Regresión lineal múltiple. Universitat Oberta de Catalunya

T. Gutiérrez (2017) Práctica 2: Limpieza y validación de los datos

D. Liviano y M. Pujol (2019) Análisis de datos y estadística con R y R-commander. Universitat Oberta de Catalunya. 

D. Liviano y M. Pujol (2019) Modelos de regresión y análisis multivarible con R-commander. Universitat Oberta de Catalunya. 

L. Subirats, D.O. Oswaldo, M. Calvo (2019) Introducción a la limpieza y análisis de los datos. Universitat Oberta de Catalunya

Jason W. Osborne (2010). Data Cleaning Basics: Best Practices in Dealing with Extreme Scores. Newborn and Infant Nursing Reviews; 10 (1): pp. 1527-3369.

A. Sethi, (2020) Support Vector Regression Tutorial for Machine Learning. URL: https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/
